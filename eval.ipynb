{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate rouge_score bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py-readability-metrics\n",
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U 'spacy[cuda-autodetect]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textdescriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import json\n",
    "import math\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/cnn_curie.json') as f:\n",
    "    cnn_pred = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/cnn_sample.json') as f:\n",
    "    cnn_ref = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Photographer James Oatway captured the attack on Mozambican Emmanuel Sithole that left him dead in broad daylight. The attackers looked like hardened thugs, and wanted one thing and that was to kill Emmanuel. Oatway tried to get as close as possible, conscious that the attackers were aware of his presence, but they finally moved on and left Sithole alone. Oatway\\'s series of images of the ordeal landed on the front page of South Africa\\'s Sunday Times under the headline, \"Kill thy neighbor: Alex attack brings home SA\\'s shame.\" Seven people have been killed in the latest round of xenophobic violence against poorer immigrants, many from South Africa\\'s neighbors. Xenophobic attacks: How did we get here?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_re[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.45, 'rouge2': 0.0, 'rougeL': 0.45, 'rougeLsum': 0.45}\n"
     ]
    }
   ],
   "source": [
    "rouge = load('rouge')\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hi there\", \"general Obii Van\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                      references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9999998807907104, 1.0],\n",
       " 'recall': [0.9999998807907104, 1.0],\n",
       " 'f1': [0.9999998807907104, 1.0],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.27.4)'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 234 ms, sys: 0 ns, total: 234 ms\n",
      "Wall time: 227 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.7684018611907959],\n",
       " 'recall': [0.8173803687095642],\n",
       " 'f1': [0.792134702205658],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.27.4)'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bertscore.compute(predictions=[cnn_pred[0]], references=[cnn_ref[0]], lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<textdescriptives.components.readability.Readability at 0x7f6bceda5ac0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import textdescriptives as td\n",
    "nlp_read = spacy.blank(\"en\")\n",
    "nlp_read.add_pipe(\"textdescriptives/readability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_order_coherence': 0.7807351499795914,\n",
       " 'second_order_coherence': 0.7494750618934631}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_coh = spacy.load(\"en_core_web_lg\")\n",
    "nlp_coh.add_pipe(\"textdescriptives/coherence\")\n",
    "doc = nlp_coh(\"The world is changed. I feel it in the water. I feel it in the earth. I smell it in the air. Much that once was is lost, for none now live who remember it.\")\n",
    "\n",
    "# all attributes are stored as a dict in the ._.coherence attribute\n",
    "doc._.coherence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69aa910d0f3045f48bacfd5a1b128817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4462c8bbcc58460bac6d3062468bd0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1192ae0ea61e493890bb3f9aa568fc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa51e254fc74e1fb1975116f4f5e2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'NEGATIVE', 'score': 0.9943841695785522}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(cnn_pred[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9348874688148499},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997125267982483},\n",
       " {'label': 'NEGATIVE', 'score': 0.9938111901283264},\n",
       " {'label': 'NEGATIVE', 'score': 0.9717812538146973},\n",
       " {'label': 'POSITIVE', 'score': 0.990036129951477},\n",
       " {'label': 'POSITIVE', 'score': 0.9938215017318726},\n",
       " {'label': 'POSITIVE', 'score': 0.9398972988128662},\n",
       " {'label': 'POSITIVE', 'score': 0.9674845933914185},\n",
       " {'label': 'NEGATIVE', 'score': 0.9985628724098206},\n",
       " {'label': 'NEGATIVE', 'score': 0.9922595620155334}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline([doc['summary'] for doc in cnn_ref[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(dataset, experiment, metric):\n",
    "    with open(f'data/{dataset}_sample.json') as f:\n",
    "        references = [doc['summary'] for doc in json.load(f)]\n",
    "    with open(f'results/{experiment}.json') as f:\n",
    "        predictions = json.load(f)\n",
    "    results = metric(predictions, references)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "results = defaultdict(lambda: defaultdict(dict))\n",
    "metrics = {\n",
    "'rouge': lambda p,r: rouge.compute(predictions=p, references=r),\n",
    "'bertscore': lambda p,r: bertscore.compute(predictions=p, references=r, lang=\"en\"),\n",
    "'readability': lambda p,r: [nlp_read(pr)._.readability for pr in p],\n",
    "'coherence': lambda p,r: [nlp_coh(pr)._.coherence for pr in p],\n",
    "'sentiment': lambda p,r: sentiment_pipeline(p),\n",
    "}\n",
    "\n",
    "\n",
    "for dataset in ['cnn', 'xsum', 'newsroom']:\n",
    "    for exp in ['eleuther1b', 'curie', 'style_curie', 'davinci', 'style_davinci', 'brio']:\n",
    "        for m_name, metric in metrics.items():\n",
    "            results[dataset][exp][m_name] = run_eval(dataset, f'{dataset}_{exp}', metric)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eval/eval.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eval/eval.json') as f:\n",
    "    reload_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, dataset_dict in reload_results.items():\n",
    "    for exp, exp_dict in dataset_dict.items():\n",
    "        for metric, metric_dict in exp_dict.items():\n",
    "            if metric == 'readability' or metric == 'coherence':\n",
    "                metric_dict = {k: [dic[k] for dic in metric_dict] for k in metric_dict[0]}\n",
    "                for submetric, submetric_list in metric_dict.items():\n",
    "                    not_nan_list = [e for e in submetric_list if not math.isnan(e)]\n",
    "                    metric_dict[submetric] = sum(not_nan_list)/len(not_nan_list) if len(not_nan_list) > 0 else 0\n",
    "                exp_dict[metric] = metric_dict\n",
    "                \n",
    "            if metric == 'bertscore':\n",
    "                del metric_dict['hashcode']\n",
    "                for submetric, submetric_list in metric_dict.items():\n",
    "                    if type(submetric_list) is list:\n",
    "                        metric_dict[submetric] = sum(submetric_list)/len(submetric_list)\n",
    "\n",
    "        \n",
    "            if metric == 'sentiment':\n",
    "                metric_list = metric_dict\n",
    "                exp_dict[metric] = {'positive_rate': sum([e['label'] == 'POSITIVE' for e in metric_list])/len(metric_list)}\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cnn': {'eleuther1b': {'rouge': {'rouge1': 0.2648411725811938,\n",
       "    'rouge2': 0.09381832710197169,\n",
       "    'rougeL': 0.18282601747648564,\n",
       "    'rougeLsum': 0.18325840373768898},\n",
       "   'bertscore': {'precision': 0.8530396234989166,\n",
       "    'recall': 0.8624498534202576,\n",
       "    'f1': 0.8573568445444107},\n",
       "   'readability': {'flesch_reading_ease': 70.36363053081172,\n",
       "    'flesch_kincaid_grade': 8.882589694152609,\n",
       "    'smog': 9.833532052208998,\n",
       "    'gunning_fog': 11.778323965879077,\n",
       "    'automated_readability_index': 11.438746698749439,\n",
       "    'coleman_liau_index': 10.016228074391494,\n",
       "    'lix': 44.222421996991024,\n",
       "    'rix': 4.913555555555556},\n",
       "   'coherence': {'first_order_coherence': 0.7992374857731618,\n",
       "    'second_order_coherence': 0.7528428209088153},\n",
       "   'sentiment': {'positive_rate': 0.42}},\n",
       "  'curie': {'rouge': {'rouge1': 0.3208694843107881,\n",
       "    'rouge2': 0.1265278551141452,\n",
       "    'rougeL': 0.21450751041668298,\n",
       "    'rougeLsum': 0.21543013315184642},\n",
       "   'bertscore': {'precision': 0.8608401000499726,\n",
       "    'recall': 0.888302788734436,\n",
       "    'f1': 0.8741824805736542},\n",
       "   'readability': {'flesch_reading_ease': 66.89419602979656,\n",
       "    'flesch_kincaid_grade': 9.825659991547385,\n",
       "    'smog': 10.57801626075382,\n",
       "    'gunning_fog': 12.647183926668667,\n",
       "    'automated_readability_index': 12.671375279609636,\n",
       "    'coleman_liau_index': 10.637266667823399,\n",
       "    'lix': 47.35851890657384,\n",
       "    'rix': 5.622341269841269},\n",
       "   'coherence': {'first_order_coherence': 0.799589254822568,\n",
       "    'second_order_coherence': 0.7862166883480369},\n",
       "   'sentiment': {'positive_rate': 0.41}},\n",
       "  'style_curie': {'rouge': {'rouge1': 0.3167528418671507,\n",
       "    'rouge2': 0.10955927344407046,\n",
       "    'rougeL': 0.21438368837339727,\n",
       "    'rougeLsum': 0.21391087777719048},\n",
       "   'bertscore': {'precision': 0.8704450011253357,\n",
       "    'recall': 0.8819353538751602,\n",
       "    'f1': 0.8759288287162781},\n",
       "   'readability': {'flesch_reading_ease': 65.18070794571676,\n",
       "    'flesch_kincaid_grade': 9.986788803642572,\n",
       "    'smog': 10.91579412879337,\n",
       "    'gunning_fog': 12.81713793274909,\n",
       "    'automated_readability_index': 12.886972301733788,\n",
       "    'coleman_liau_index': 11.105280934919,\n",
       "    'lix': 48.346124075252774,\n",
       "    'rix': 5.807142857142858},\n",
       "   'coherence': {'first_order_coherence': 0.8080558107331482,\n",
       "    'second_order_coherence': 0.8023862860936632},\n",
       "   'sentiment': {'positive_rate': 0.46}},\n",
       "  'davinci': {'rouge': {'rouge1': 0.34289394879496843,\n",
       "    'rouge2': 0.12970010074846672,\n",
       "    'rougeL': 0.22906375282907865,\n",
       "    'rougeLsum': 0.22906396614849656},\n",
       "   'bertscore': {'precision': 0.8670049208402634,\n",
       "    'recall': 0.8939856702089309,\n",
       "    'f1': 0.8802259343862534},\n",
       "   'readability': {'flesch_reading_ease': 65.48524837081499,\n",
       "    'flesch_kincaid_grade': 9.661417224874505,\n",
       "    'smog': 10.852651932840493,\n",
       "    'gunning_fog': 12.426946259910153,\n",
       "    'automated_readability_index': 12.422230932919922,\n",
       "    'coleman_liau_index': 11.191639566676283,\n",
       "    'lix': 47.124690434111415,\n",
       "    'rix': 5.53},\n",
       "   'coherence': {'first_order_coherence': 0.7909908747176331,\n",
       "    'second_order_coherence': 0.7918473167050165},\n",
       "   'sentiment': {'positive_rate': 0.49}},\n",
       "  'style_davinci': {'rouge': {'rouge1': 0.3280254950963726,\n",
       "    'rouge2': 0.11647692956672623,\n",
       "    'rougeL': 0.21661653588085594,\n",
       "    'rougeLsum': 0.21733509412900465},\n",
       "   'bertscore': {'precision': 0.8636375260353089,\n",
       "    'recall': 0.8936672323942184,\n",
       "    'f1': 0.8783296030759812},\n",
       "   'readability': {'flesch_reading_ease': 62.00420624721866,\n",
       "    'flesch_kincaid_grade': 10.744794382775655,\n",
       "    'smog': 11.450903877947084,\n",
       "    'gunning_fog': 13.515206156478321,\n",
       "    'automated_readability_index': 13.72820497699792,\n",
       "    'coleman_liau_index': 11.44098483653246,\n",
       "    'lix': 50.26463243477774,\n",
       "    'rix': 6.332999999999999},\n",
       "   'coherence': {'first_order_coherence': 0.8101064193248747,\n",
       "    'second_order_coherence': 0.8101470645027932},\n",
       "   'sentiment': {'positive_rate': 0.5}},\n",
       "  'brio': {'rouge': {'rouge1': 0.11689510501844186,\n",
       "    'rouge2': 0.004547909897384009,\n",
       "    'rougeL': 0.08438661581902596,\n",
       "    'rougeLsum': 0.08441073871447465},\n",
       "   'bertscore': {'precision': 0.8064801853895187,\n",
       "    'recall': 0.8158196794986725,\n",
       "    'f1': 0.8110045218467712},\n",
       "   'readability': {'flesch_reading_ease': 74.39623357579457,\n",
       "    'flesch_kincaid_grade': 6.462019956331256,\n",
       "    'smog': 9.288526003277372,\n",
       "    'gunning_fog': 9.518669951206283,\n",
       "    'automated_readability_index': 8.139851382077696,\n",
       "    'coleman_liau_index': 10.009494603724475,\n",
       "    'lix': 38.0532049360449,\n",
       "    'rix': 3.4015000000000004},\n",
       "   'coherence': {'first_order_coherence': 0.7526662206401425,\n",
       "    'second_order_coherence': 0.7410407694987952},\n",
       "   'sentiment': {'positive_rate': 0.4}}},\n",
       " 'xsum': {'eleuther1b': {'rouge': {'rouge1': 0.19216575193822238,\n",
       "    'rouge2': 0.03665673412449484,\n",
       "    'rougeL': 0.1423462274260064,\n",
       "    'rougeLsum': 0.14198781420453652},\n",
       "   'bertscore': {'precision': 0.8524647700786591,\n",
       "    'recall': 0.8576820302009582,\n",
       "    'f1': 0.8548228120803834},\n",
       "   'readability': {'flesch_reading_ease': 73.02106393620511,\n",
       "    'flesch_kincaid_grade': 7.714781222058076,\n",
       "    'smog': 8.156725610938903,\n",
       "    'gunning_fog': 10.465841638920779,\n",
       "    'automated_readability_index': 9.405096974393818,\n",
       "    'coleman_liau_index': 9.220309527287577,\n",
       "    'lix': 40.32247676214457,\n",
       "    'rix': 4.0275},\n",
       "   'coherence': {'first_order_coherence': 0.7585859832453862,\n",
       "    'second_order_coherence': 0.6770894302185191},\n",
       "   'sentiment': {'positive_rate': 0.47}},\n",
       "  'curie': {'rouge': {'rouge1': 0.23115598888397185,\n",
       "    'rouge2': 0.044858632564158674,\n",
       "    'rougeL': 0.164918534750292,\n",
       "    'rougeLsum': 0.16421710252646493},\n",
       "   'bertscore': {'precision': 0.8661361438035965,\n",
       "    'recall': 0.8705973428487778,\n",
       "    'f1': 0.8681318771839142},\n",
       "   'readability': {'flesch_reading_ease': 66.62553934642159,\n",
       "    'flesch_kincaid_grade': 9.455830721578712,\n",
       "    'smog': 10.6614642963235,\n",
       "    'gunning_fog': 12.232491776390265,\n",
       "    'automated_readability_index': 12.03329594501812,\n",
       "    'coleman_liau_index': 10.719769844668452,\n",
       "    'lix': 46.39463751249732,\n",
       "    'rix': 5.3375},\n",
       "   'coherence': {'first_order_coherence': 0.7935513108140894,\n",
       "    'second_order_coherence': 0.7887268075719476},\n",
       "   'sentiment': {'positive_rate': 0.44}},\n",
       "  'style_curie': {'rouge': {'rouge1': 0.23896175269500464,\n",
       "    'rouge2': 0.0557881123766085,\n",
       "    'rougeL': 0.1707415487312103,\n",
       "    'rougeLsum': 0.1706985123628815},\n",
       "   'bertscore': {'precision': 0.8691867411136627,\n",
       "    'recall': 0.8735993933677674,\n",
       "    'f1': 0.8711562383174897},\n",
       "   'readability': {'flesch_reading_ease': 63.13065197067464,\n",
       "    'flesch_kincaid_grade': 10.145973040733328,\n",
       "    'smog': 11.261704438426527,\n",
       "    'gunning_fog': 13.076501664321668,\n",
       "    'automated_readability_index': 13.134913873684484,\n",
       "    'coleman_liau_index': 11.648516844091604,\n",
       "    'lix': 49.383179529749306,\n",
       "    'rix': 6.121944444444445},\n",
       "   'coherence': {'first_order_coherence': 0.7971991241429791,\n",
       "    'second_order_coherence': 0.7885265817411807},\n",
       "   'sentiment': {'positive_rate': 0.49}},\n",
       "  'davinci': {'rouge': {'rouge1': 0.2599762941367614,\n",
       "    'rouge2': 0.07381273991352431,\n",
       "    'rougeL': 0.18514225028544784,\n",
       "    'rougeLsum': 0.18537452282546824},\n",
       "   'bertscore': {'precision': 0.8678686803579331,\n",
       "    'recall': 0.8797610068321228,\n",
       "    'f1': 0.873605780005455},\n",
       "   'readability': {'flesch_reading_ease': 51.529935342871894,\n",
       "    'flesch_kincaid_grade': 14.157021607022598,\n",
       "    'smog': 0,\n",
       "    'gunning_fog': 17.140731234794192,\n",
       "    'automated_readability_index': 18.119577673837593,\n",
       "    'coleman_liau_index': 12.2838147032325,\n",
       "    'lix': 59.179880068063746,\n",
       "    'rix': 8.585},\n",
       "   'coherence': {'first_order_coherence': 0.6038962602615356,\n",
       "    'second_order_coherence': 0.536014162003994},\n",
       "   'sentiment': {'positive_rate': 0.54}},\n",
       "  'style_davinci': {'rouge': {'rouge1': 0.25009661854135723,\n",
       "    'rouge2': 0.05730849149783705,\n",
       "    'rougeL': 0.17285115033414994,\n",
       "    'rougeLsum': 0.1725305786835173},\n",
       "   'bertscore': {'precision': 0.8620074087381363,\n",
       "    'recall': 0.8811299568414688,\n",
       "    'f1': 0.8713055205345154},\n",
       "   'readability': {'flesch_reading_ease': 41.701415322805495,\n",
       "    'flesch_kincaid_grade': 17.025922862776547,\n",
       "    'smog': 0,\n",
       "    'gunning_fog': 20.082821195228732,\n",
       "    'automated_readability_index': 21.644819662872333,\n",
       "    'coleman_liau_index': 13.091250236901006,\n",
       "    'lix': 66.59027826919984,\n",
       "    'rix': 10.77},\n",
       "   'coherence': {'first_order_coherence': 0.5906576414903004,\n",
       "    'second_order_coherence': 0.5481462776660919},\n",
       "   'sentiment': {'positive_rate': 0.51}},\n",
       "  'brio': {'rouge': {'rouge1': 0.4178365962003149,\n",
       "    'rouge2': 0.1941642943130354,\n",
       "    'rougeL': 0.3313473962695538,\n",
       "    'rougeLsum': 0.33081102772975807},\n",
       "   'bertscore': {'precision': 0.9117612355947494,\n",
       "    'recall': 0.9043348789215088,\n",
       "    'f1': 0.9078872925043107},\n",
       "   'readability': {'flesch_reading_ease': 67.20005211041789,\n",
       "    'flesch_kincaid_grade': 9.333050946773868,\n",
       "    'smog': 0,\n",
       "    'gunning_fog': 12.028941205418,\n",
       "    'automated_readability_index': 11.576914826952288,\n",
       "    'coleman_liau_index': 10.278526945517594,\n",
       "    'lix': 44.46982750608123,\n",
       "    'rix': 4.85},\n",
       "   'coherence': {'first_order_coherence': 0.5410997333625952,\n",
       "    'second_order_coherence': 0.6544644832611084},\n",
       "   'sentiment': {'positive_rate': 0.48}}},\n",
       " 'newsroom': {'eleuther1b': {'rouge': {'rouge1': 0.17413959636767612,\n",
       "    'rouge2': 0.03168056440020979,\n",
       "    'rougeL': 0.1247093081015406,\n",
       "    'rougeLsum': 0.12456897859607391},\n",
       "   'bertscore': {'precision': 0.8289624768495559,\n",
       "    'recall': 0.8337893897294998,\n",
       "    'f1': 0.8310097163915634},\n",
       "   'readability': {'flesch_reading_ease': 69.49430837328026,\n",
       "    'flesch_kincaid_grade': 9.008154664959935,\n",
       "    'smog': 9.735764842364473,\n",
       "    'gunning_fog': 12.114095382979048,\n",
       "    'automated_readability_index': 10.781495347082625,\n",
       "    'coleman_liau_index': 9.048757894801634,\n",
       "    'lix': 44.080272028696456,\n",
       "    'rix': 4.943075396825396},\n",
       "   'coherence': {'first_order_coherence': 0.8547399028342803,\n",
       "    'second_order_coherence': 0.8381328896831948},\n",
       "   'sentiment': {'positive_rate': 0.44}},\n",
       "  'curie': {'rouge': {'rouge1': 0.21922713431940338,\n",
       "    'rouge2': 0.0404818416033019,\n",
       "    'rougeL': 0.14417282509082044,\n",
       "    'rougeLsum': 0.14412809001014887},\n",
       "   'bertscore': {'precision': 0.8454005289077758,\n",
       "    'recall': 0.8504160279035569,\n",
       "    'f1': 0.8477166867256165},\n",
       "   'readability': {'flesch_reading_ease': 63.75166116152266,\n",
       "    'flesch_kincaid_grade': 10.140497991955439,\n",
       "    'smog': 11.10522815659508,\n",
       "    'gunning_fog': 13.249875545440709,\n",
       "    'automated_readability_index': 12.83373505793722,\n",
       "    'coleman_liau_index': 11.062924879663699,\n",
       "    'lix': 48.302738588512256,\n",
       "    'rix': 5.8002063492063485},\n",
       "   'coherence': {'first_order_coherence': 0.8122147238982048,\n",
       "    'second_order_coherence': 0.7738088738885397},\n",
       "   'sentiment': {'positive_rate': 0.44}},\n",
       "  'style_curie': {'rouge': {'rouge1': 0.22276562962967997,\n",
       "    'rouge2': 0.0448406070165422,\n",
       "    'rougeL': 0.14606986165051122,\n",
       "    'rougeLsum': 0.1468169783662082},\n",
       "   'bertscore': {'precision': 0.8522314798831939,\n",
       "    'recall': 0.8505538338422776,\n",
       "    'f1': 0.851232538819313},\n",
       "   'readability': {'flesch_reading_ease': 63.58427781034948,\n",
       "    'flesch_kincaid_grade': 10.11309236411989,\n",
       "    'smog': 10.976501197025337,\n",
       "    'gunning_fog': 13.007872134954141,\n",
       "    'automated_readability_index': 12.700833315295045,\n",
       "    'coleman_liau_index': 11.06000279077104,\n",
       "    'lix': 48.06339839404558,\n",
       "    'rix': 5.694333333333334},\n",
       "   'coherence': {'first_order_coherence': 0.8258186966714894,\n",
       "    'second_order_coherence': 0.8004701925949617},\n",
       "   'sentiment': {'positive_rate': 0.49}},\n",
       "  'davinci': {'rouge': {'rouge1': 0.23757165685836784,\n",
       "    'rouge2': 0.046972573001534124,\n",
       "    'rougeL': 0.15862207033114106,\n",
       "    'rougeLsum': 0.15866733554759202},\n",
       "   'bertscore': {'precision': 0.8501121139526367,\n",
       "    'recall': 0.8541187137365341,\n",
       "    'f1': 0.8519820934534073},\n",
       "   'readability': {'flesch_reading_ease': 57.214363033127036,\n",
       "    'flesch_kincaid_grade': 11.687187063149343,\n",
       "    'smog': 11.269576902458668,\n",
       "    'gunning_fog': 14.566676377046829,\n",
       "    'automated_readability_index': 14.740271875088022,\n",
       "    'coleman_liau_index': 12.0107890814392,\n",
       "    'lix': 53.529243261187595,\n",
       "    'rix': 7.148500000000001},\n",
       "   'coherence': {'first_order_coherence': 0.8406945814689001,\n",
       "    'second_order_coherence': 0.8076635109165967},\n",
       "   'sentiment': {'positive_rate': 0.63}},\n",
       "  'style_davinci': {'rouge': {'rouge1': 0.2325731284035395,\n",
       "    'rouge2': 0.041669022416835455,\n",
       "    'rougeL': 0.14969744787407013,\n",
       "    'rougeLsum': 0.14990426368084803},\n",
       "   'bertscore': {'precision': 0.8468222522735596,\n",
       "    'recall': 0.854907888174057,\n",
       "    'f1': 0.8507260811328888},\n",
       "   'readability': {'flesch_reading_ease': 55.138965453483436,\n",
       "    'flesch_kincaid_grade': 12.403214018702473,\n",
       "    'smog': 12.348105239892737,\n",
       "    'gunning_fog': 15.383545834932228,\n",
       "    'automated_readability_index': 15.698363902453883,\n",
       "    'coleman_liau_index': 12.258350287478624,\n",
       "    'lix': 55.55591791186599,\n",
       "    'rix': 7.649166666666668},\n",
       "   'coherence': {'first_order_coherence': 0.8354644127686819,\n",
       "    'second_order_coherence': 0.8192728253928098},\n",
       "   'sentiment': {'positive_rate': 0.64}},\n",
       "  'brio': {'rouge': {'rouge1': 0.2461051777157116,\n",
       "    'rouge2': 0.06647116981253295,\n",
       "    'rougeL': 0.16951279437702693,\n",
       "    'rougeLsum': 0.16998897875946567},\n",
       "   'bertscore': {'precision': 0.8750909334421157,\n",
       "    'recall': 0.8497404980659485,\n",
       "    'f1': 0.8620883458852768},\n",
       "   'readability': {'flesch_reading_ease': 66.43148872337537,\n",
       "    'flesch_kincaid_grade': 10.202923735983115,\n",
       "    'smog': 0,\n",
       "    'gunning_fog': 13.245835753061456,\n",
       "    'automated_readability_index': 12.560744754474738,\n",
       "    'coleman_liau_index': 9.711461472351584,\n",
       "    'lix': 46.45979747503514,\n",
       "    'rix': 5.485},\n",
       "   'coherence': {'first_order_coherence': 0.8603910207748413,\n",
       "    'second_order_coherence': 0},\n",
       "   'sentiment': {'positive_rate': 0.51}}}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eval/eval_agg.json', 'w') as f:\n",
    "    json.dump(reload_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(dataset):\n",
    "    cols = ['model']+[submetric for metric, metric_dict in reload_results[dataset]['curie'].items() \n",
    "                     for submetric, val in metric_dict.items()]\n",
    "\n",
    "\n",
    "\n",
    "    vals = [[exp] + [val for metric, metric_dict in exp_dict.items() \n",
    "                     for submetric, val in metric_dict.items()]\n",
    "                for exp, exp_dict in reload_results[dataset].items()]\n",
    "    \n",
    "    html = tabulate(vals, headers=cols, tablefmt=\"html\")\n",
    "    with open(f'eval/eval_table_{dataset}.html', 'w') as f:\n",
    "        f.write(html)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_table('cnn')\n",
    "save_table('newsroom')\n",
    "save_table('xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
